{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogananda26/Machine_Learning/blob/master/Result_Group_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5cmVVhL5ewO_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2jVYW0H5MjD"
      },
      "outputs": [],
      "source": [
        "# this is for importing the thing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# we use randomforest classfier for predicting thing on discrete way\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# we can changging the parameter for better result\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn import svm\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWMXlHMA7LHh"
      },
      "source": [
        "# Fetching Data In Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c4wrF0I7Klj"
      },
      "outputs": [],
      "source": [
        "#this is for inserting the csv file from web\n",
        "!wget \"https://raw.githubusercontent.com/yogananda26/Mechine_Learning/master/weatherAUS.csv/weatherAUS.csv\"\n",
        "df = pd.read_csv(\"weatherAUS.csv\")\n",
        "# this is for printing the data\n",
        "df.describe"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Describing Data"
      ],
      "metadata": {
        "id": "EAbbofB5NPVc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "3b1G43XGOVD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is for dropping the data that outlier\n",
        "df.drop(index=df[df[\"WindGustSpeed\"]>60].index, inplace=True)\n",
        "df.drop(index=df[df[\"Rainfall\"]>2].index, inplace=True)\n",
        "df.drop(index=df[df[\"WindSpeed9am\"]>22].index, inplace=True)"
      ],
      "metadata": {
        "id": "6ejx7USnZUdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "_rIhteZkgNYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drop Some Value"
      ],
      "metadata": {
        "id": "UCjmi5fNNPfI"
      }
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "df['MinTemp'].plot(kind='hist', bins=20, title='MinTemp')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ccnkj8cWPnAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Displaying the Data  "
      ],
      "metadata": {
        "id": "lrpl9Yf5NT7N"
      }
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "plt.subplots(figsize=(8, 8))\n",
        "df_2dhist = pd.DataFrame({\n",
        "    x_label: grp['RainTomorrow'].value_counts()\n",
        "    for x_label, grp in df.groupby('RainToday')\n",
        "})\n",
        "sns.heatmap(df_2dhist, cmap='viridis')\n",
        "plt.xlabel('RainToday')\n",
        "_ = plt.ylabel('RainTomorrow')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "6z_Nlh7UPbcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sb\n",
        "fig, ax = plt.subplots(figsize=(13, 10))\n",
        "sb.heatmap(df.corr(), annot=True)\n",
        "# fig, ax = plt.subplots(figsize=(10, 10))\n"
      ],
      "metadata": {
        "id": "_yZE9Rf-Wyjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0\n",
        "for label in df[:-1] :\n",
        "  print(i, label, df[label].isna().sum(), df[label].dtype)\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "yRDlDdAHNNIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "1up9ta40OLFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Selection"
      ],
      "metadata": {
        "id": "APnNP5s9Nfd-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFASo_xzVTnp"
      },
      "outputs": [],
      "source": [
        "# this is for starting the mechine learning\n",
        "X = df.iloc[: , [1,2,3,4,7,8,9,10,11,12,15,16,17,18,21]].values\n",
        "Y = df.iloc[: , -1].values\n",
        "Y = Y.reshape(-1, 1)\n",
        "\n",
        "print(X)\n",
        "# this is for output\n",
        "print(\"this is for output\")\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD2BwWbwQSzq"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIKwZXv3QOho"
      },
      "outputs": [],
      "source": [
        "# this is for filling the dataset wether the dataset had nan value\n",
        "imp_most_frequent = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
        "X = imp_most_frequent.fit_transform(X)\n",
        "Y = imp_most_frequent.fit_transform(Y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[: , 0]"
      ],
      "metadata": {
        "id": "WptjUuZap4Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tovt62bQ6btr"
      },
      "source": [
        "this is for translate the text into number for simple processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq_SDaDvV9fP"
      },
      "outputs": [],
      "source": [
        "# this is for changing the coloumn\n",
        "fit0 = LabelEncoder()\n",
        "X[: , 0] = fit0.fit_transform(X[:,0])\n",
        "fit = LabelEncoder()\n",
        "X[: , 4] = fit.fit_transform(X[:,4])\n",
        "fit1 = LabelEncoder()\n",
        "X[: ,6] = fit.fit_transform(X[: , 6])\n",
        "fit2 = LabelEncoder()\n",
        "X[: , 7] = fit2.fit_transform(X[:,7])\n",
        "fit3 = LabelEncoder()\n",
        "\n",
        "X[: , -1] = fit3.fit_transform(X[:,-1])\n",
        "\n",
        "# this is for changing the graph Y\n",
        "fit_y = LabelEncoder()\n",
        "Y = fit_y.fit_transform(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgIiliOH_ncz"
      },
      "source": [
        "#Feature Scalling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTlmlymPenYf"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7kzq-z9e_lN"
      },
      "outputs": [],
      "source": [
        "print(len(Y==0))\n",
        "print(len(Y==1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1m2QQLeeADb3"
      },
      "source": [
        "Splitting Training And Testing Model (more training you have better result youll get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oOHm7YAe_-6O"
      },
      "outputs": [],
      "source": [
        "# this is for spliting the data into testing and training test\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "print(X_train)\n",
        "print(\"=======================================================\")\n",
        "print(X_test)\n",
        "print(\"=======================================================\")\n",
        "print(Y_train)\n",
        "print(\"=======================================================\")\n",
        "print(Y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opjz_-N7dpbP"
      },
      "outputs": [],
      "source": [
        "print(len(Y == 1))\n",
        "print(len(Y == 0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8QNpKn2GTdk"
      },
      "source": [
        "# Training The Model\n",
        "\n",
        "Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMlUlg8X90ou"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ppp5HH096AY"
      },
      "outputs": [],
      "source": [
        "nn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "nn_model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='binary_crossentropy',\n",
        "                 metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "history = nn_model.fit(\n",
        "    X_train, Y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0\n",
        ")"
      ],
      "metadata": {
        "id": "EZZJtFFM-7yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = nn_model.fit(X_train, Y_train,\n",
        "                       batch_size=32,\n",
        "                       epochs=100,\n",
        "                       validation_split=0.2\n",
        "                       )"
      ],
      "metadata": {
        "id": "TKMqdv7FuPW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_NOSVOTBvR0"
      },
      "outputs": [],
      "source": [
        "def plot_loss(history) :\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss', color='r')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Binary crosstrentropy')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "\n",
        "def accuracy(history) :\n",
        "  plt.plot(history.history['accuracy'], label='accuracy', color='r')\n",
        "  plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGIW0q2pAVKX"
      },
      "outputs": [],
      "source": [
        "plot_loss(history)\n",
        "accuracy(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OXaDfVwdN6n"
      },
      "source": [
        "#Searching The Best Algorithm For This Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uvRX69lpJtxu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta43HYB3GS37"
      },
      "outputs": [],
      "source": [
        "model_params = {\n",
        "    'random_forest' : {\n",
        "        'model' : RandomForestClassifier(),\n",
        "        'params' : {\n",
        "        # ! dont take to much 'n_estimators' , cuz can cause overfitting\n",
        "            'n_estimators' : [100],\n",
        "            'random_state' : [0],\n",
        "            'criterion' : ['gini', 'entropy', 'log_loss'],\n",
        "            'class_weight' : ['balanced', 'balanced_subsample'],\n",
        "            'max_features' : ['sqrt', 'log2', None]\n",
        "          }\n",
        "      },\n",
        "    'svm': {\n",
        "        'model': svm.SVC(),\n",
        "        'params' : {\n",
        "          # ! dont use very tiny number of 'tol' cuz can cause overfitting\n",
        "            'tol' : [0.01],\n",
        "            'C': [30],\n",
        "            'kernel': ['rbf'],\n",
        "            'gamma' :['auto'],\n",
        "            'decision_function_shape' : ['ovr']\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86OFKHhmSmM8"
      },
      "outputs": [],
      "source": [
        "scores = []\n",
        "for model_name, mp in model_params.items():\n",
        "    clf =  GridSearchCV(mp['model'], mp['params'],return_train_score=False)\n",
        "    clf.fit(X_train, Y_train.reshape(-1,))\n",
        "    scores.append({\n",
        "        'model': model_name,\n",
        "        'best_score': clf.best_score_,\n",
        "        'best_params': clf.best_params_\n",
        "    })\n",
        "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FCobhu8IxdM"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_-3VulWLsrf"
      },
      "outputs": [],
      "source": [
        "random_forest = RandomForestClassifier(class_weight='balanced_subsample',\n",
        "                                       criterion='entropy',\n",
        "                                       max_features=None,\n",
        "                                       n_estimators=100,\n",
        "                                       random_state=0)\n",
        "random_forest.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CTest  = random_forest.predict(X_test)\n",
        "CTrain  = random_forest.predict(X_train)\n",
        "print(\"Train set acc: \", metrics.accuracy_score(Y_train, CTrain))\n",
        "print(\"Test set acc: \", metrics.accuracy_score(Y_test, CTest))"
      ],
      "metadata": {
        "id": "v9elttgUmE2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVC = svm.SVC(C=30,\n",
        "              decision_function_shape='ovr',\n",
        "              gamma='auto',\n",
        "              kernel='rbf',\n",
        "              tol=0.01)\n",
        "SVC.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "iPODkmmHxNJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machine"
      ],
      "metadata": {
        "id": "tW3UInfCOupQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CTest  = SVC.predict(X_test)\n",
        "CTrain  = SVC.predict(X_train)\n",
        "print(\"Train set acc: \", metrics.accuracy_score(Y_train, CTrain))\n",
        "print(\"Test set acc: \", metrics.accuracy_score(Y_test, CTest))"
      ],
      "metadata": {
        "id": "hNlBMMfjp2aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3no3BTBFL1t8"
      },
      "outputs": [],
      "source": [
        "Y_predict = fit_y.inverse_transform(CTrain)\n",
        "Y_test = fit_y.inverse_transform(CTest)\n",
        "Y_predict = Y_predict.reshape(-1,1)\n",
        "Y_test = Y_test.reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbJjflmoNTnU"
      },
      "outputs": [],
      "source": [
        "# this is for displaying the result\n",
        "func = np.concatenate((Y_test, Y_predict), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcHO-L07Si0G"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data=func, columns=[\"Tommorow Raining\", \"Prediction of Raining\"])\n",
        "print(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}